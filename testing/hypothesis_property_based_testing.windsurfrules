# Windsurf Rules: Property-Based Testing (Hypothesis - Python)

## Guiding Principles

- **Goal:** Define properties (general rules or invariants) that the code should always satisfy, and let a testing framework (like Hypothesis) generate a wide range of inputs to try and falsify those properties.
- **Contrast with Example-Based Testing:** Instead of writing specific examples (`assert add(2, 3) == 5`), you define a property (`assert add(x, y) == add(y, x)` for all integers x, y) and let Hypothesis generate many `x` and `y` values.
- **Hypothesis Workflow:**
    - **Define Strategies:** Specify how to generate data using `hypothesis.strategies` (e.g., `st.integers()`, `st.text()`, `st.lists(...)`, `st.builds(...)`).
    - **Write Test Function:** Decorate a test function with `@given(...)` passing the strategies.
    - **Assert Properties:** Inside the test function, assert the properties that should hold true for *any* data generated by the strategies.
    - **Falsification:** Hypothesis searches for inputs that cause the assertions to fail (a counterexample).
    - **Shrinking:** If a counterexample is found, Hypothesis tries to simplify it to the smallest possible failing input, making debugging easier.
- **Key Concepts:**
    - **Properties:** General statements about the code's behavior (e.g., commutativity, idempotence, encoding/decoding round-trip, function never raises unexpected exceptions).
    - **Strategies:** Recipes for generating test data.
    - **`@given`:** Decorator linking strategies to test functions.
    - **`assume()`:** Use `hypothesis.assume(condition)` to discard generated examples that don't meet necessary preconditions for the test, without failing the test.
    - **Stateful Testing:** Use `st.rule()` and `RuleBasedStateMachine` for testing systems with internal state.
- **Benefits:** Finds edge cases missed by example-based tests, improves confidence in code correctness across a wider input space, encourages thinking about general code behavior.
- **Best Practices:**
    - Start with simple properties and build complexity.
    - Keep strategies reasonably targeted to the function's domain.
    - Use `assume()` judiciously to avoid discarding too many examples.
    - Integrate with standard test runners (like `pytest`).

## AI Instructions

- **Suggest Property-Based Tests:** When appropriate (e.g., for functions with complex inputs, mathematical operations, serialization/deserialization, state machines), suggest writing property-based tests using Hypothesis.
- **Generate `@given` Structure:** Generate the basic structure for a Hypothesis test:
    ```python
    from hypothesis import given
    import hypothesis.strategies as st

    @given(x=st.integers(), y=st.integers())
    def test_addition_is_commutative(x, y):
        assert my_module.add(x, y) == my_module.add(y, x)
    ```
- **Select Appropriate Strategies:** Based on the function signature or context, suggest relevant Hypothesis strategies (e.g., `st.integers()` for `int` args, `st.text()` for `str`, `st.floats()` for `float`, `st.builds(MyClass, ...)` for custom classes).
- **Identify Potential Properties:** Suggest common properties to test:
    - Commutativity/Associativity for mathematical operations.
    - Idempotence (applying a function twice yields the same result as applying it once).
    - Invariants (conditions that should always be true before/after function execution).
    - Round-tripping (e.g., `decode(encode(data)) == data`).
    - Never raising unexpected exceptions for valid inputs.
- **Explain `assume()`:** When preconditions are needed, generate code using `assume()` and explain its purpose.
- **Interpret Counterexamples:** Explain that if Hypothesis finds a failing input, it's a minimal counterexample that demonstrates a bug or violated property.
- **Combine with Example-Based:** Remind the user that property-based testing complements, rather than entirely replaces, example-based testing (which is good for specific, known edge cases or requirements).
